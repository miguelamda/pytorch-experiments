{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e405ba2-709c-4827-bca7-e698dd54b21b",
   "metadata": {},
   "source": [
    "# Reproducing Movie Tag classification model in PyTorch\n",
    "\n",
    "This notebook is my \"getting started\" notebook for PyTorch, and I will work with our dataset on Movie Tag extraction. https://doi.org/10.1109/ACCESS.2019.2963535\n",
    "\n",
    "## 1 Load the dataset\n",
    "\n",
    "We can load datasets from folders with ImageFolder. Later, we can split the dataset in test, val, train with random_split.\n",
    "\n",
    "### 1.1 Auxiliary functions for dataset\n",
    "\n",
    "Let's define a function to load the dataset:                                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4dd45a01-7715-4b1d-b82c-35efad749484",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/miguel/.local/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "\n",
    "# what: loads the movie tag dataset from a folder, and a dictionary with the label names\n",
    "# input: folder, image size, and verbosity\n",
    "# return: data object\n",
    "# example: data = load_movie_dataset('./data/Movie',[128,128])\n",
    "def load_movietag_dataset(folder,im_size=[128,128],verbose=True):\n",
    "    data = datasets.ImageFolder(\n",
    "         folder,\n",
    "         transform=transforms.Compose([transforms.ToTensor(),transforms.Resize(im_size)]),\n",
    "         target_transform=transforms.Lambda(lambda y: torch.zeros(51, dtype=torch.float).scatter_(0, torch.tensor(y), value=1))\n",
    "         )\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Loaded {len(data)} samples\")\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5d7fd9-ecc0-4a92-a01d-06270ed5f34a",
   "metadata": {},
   "source": [
    "Now let's define a function to do the splits of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adfacbf4-299f-46ee-adb5-6047fc145ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what: split the dataset in train test\n",
    "# input: dataset object, the percentage for train, verbosity\n",
    "# return: data objects for train an val\n",
    "# example: train, val = data_splits(data,0.8)\n",
    "def data_splits(dataset,tr_percent=0.8,verbose=True):\n",
    "    total_size = len(data)\n",
    "    train_size = int(np.floor(tr_percent*total_size))\n",
    "    test_size  = total_size-train_size\n",
    "    \n",
    "    # we can split the dataset randomnly like this\n",
    "    train, test = torch.utils.data.random_split(data, [train_size, test_size])\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Splitted the dataset with {len(data)} samples. Train: {len(train)}, Test: {len(test)}\")\n",
    "    \n",
    "    return train, test\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c147e53-50db-4958-a611-482181bab9b5",
   "metadata": {},
   "source": [
    "One function to check the status of the dataset (randomnly show images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66dac60c-56ba-4579-ad65-4950d03d8afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def print_random_samples(data):\n",
    "    figure = plt.figure(figsize=(8, 8))\n",
    "    cols, rows = 3, 3\n",
    "    for i in range(1, cols * rows + 1):\n",
    "        sample_idx = torch.randint(len(data), size=(1,)).item() # random number, get item because it's a random tensor\n",
    "        img, label = data[sample_idx]\n",
    "        figure.add_subplot(rows, cols, i)\n",
    "        plt.title(data.classes[torch.argmax(label).item()])\n",
    "        plt.axis(\"off\")\n",
    "        plt.imshow(transforms.ToPILImage()(img)) #, cmap=\"rgb\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf81c1d2-674f-4918-b021-3fca161eb6d4",
   "metadata": {},
   "source": [
    "The following function creates the data loaders (the iterators over the dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c50d106b-b999-4fcb-b6f5-8aeffb1fd023",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def create_data_loader(train,test,batch_size=32,cuda_avail=False):\n",
    "    train_dataloader = DataLoader(train, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=cuda_avail)\n",
    "    test_dataloader = DataLoader(test, batch_size=batch_size*2, num_workers=8, pin_memory=cuda_avail) \n",
    "    return train_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624b8c8a-0896-45b2-acea-fddf95936dcb",
   "metadata": {},
   "source": [
    "### 1.2 Auxiliary functions for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e5110d5-ce9a-4796-ba89-b38241a6442a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "def print_model(model):\n",
    "    print(model)\n",
    "    print(f\"Number of Parameters: {count_parameters(model)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6452e33-fbf9-4bf0-ac83-e0ae0abada85",
   "metadata": {},
   "source": [
    "## 2. Quick look to the dataset\n",
    "\n",
    "We will load the dataset and print a couple of random samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "435c7e43-8201-4cb1-800f-5d55fab4b646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 34664 samples\n"
     ]
    }
   ],
   "source": [
    "data = load_movietag_dataset('./data/Movie')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffea6f12-b1db-447c-87de-a9d920fc78f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print_random_samples(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02ad901-dbc6-4637-80b9-279cf68b9ffe",
   "metadata": {},
   "source": [
    "## 3. Model definition\n",
    "\n",
    "Next, we define the model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68ba861f-217f-4142-8b4d-f8818ed73180",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "resnet18 = models.resnet18(pretrained=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f37d5f8-c190-4891-9659-63b86cd92096",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class MovieRest(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MovieRest, self).__init__()      ## required!  \n",
    "        self.ResNetBlock = nn.Sequential(\n",
    "            resnet18.conv1,\n",
    "            resnet18.bn1,\n",
    "            resnet18.relu,\n",
    "            resnet18.maxpool,\n",
    "            resnet18.layer1,\n",
    "            resnet18.layer2,\n",
    "            nn.AdaptiveAvgPool2d(output_size=(1, 1))\n",
    "        )\n",
    "        self.Classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=128, out_features=51, bias=True)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        convX = self.ResNetBlock(x)\n",
    "        return self.Classifier(convX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a3ce130c-fa51-4959-9d97-756dc7d0a9db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 51])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelRest = MovieRest()\n",
    "\n",
    "#modelRest(train_features).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f8c1eaea-f5ba-4efe-8420-b183fbb2c259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MovieRest(\n",
      "  (ResNetBlock): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (4): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (6): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  )\n",
      "  (Classifier): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=128, out_features=51, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#print(resnet18)\n",
    "print(modelRest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d95cd6b-c0ed-4394-831d-f37cbdedf48e",
   "metadata": {},
   "source": [
    "## 4. Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcce6af-dd47-4dc4-962f-a52537ea5679",
   "metadata": {},
   "source": [
    "### 4.1. Check CUDA installation\n",
    "\n",
    "Let's check if we have CUDA on the server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4226e872-1e73-484a-9bef-b5cb22671021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda:1 device\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce RTX 2080'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuda_enabled = torch.cuda.is_available()\n",
    "\n",
    "device = \"cuda:1\" if cuda_enabled else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "torch.cuda.get_device_name(torch.cuda.device(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad1fa02-5498-478c-9128-c40587880583",
   "metadata": {},
   "source": [
    "### 4.2. Load the dataset and create data loaders\n",
    "Load the dataset and split in test and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d5eb2e7-47a3-48f2-a4b9-82a7ac933161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 34664 samples\n",
      "Splitted the dataset with 34664 samples. Train: 27731, Test: 6933\n"
     ]
    }
   ],
   "source": [
    "image_res=[128,128]  # input resolution to the model\n",
    "\n",
    "# load the dataset\n",
    "data = load_movietag_dataset('./data/Movie',image_res)\n",
    "\n",
    "# split the data\n",
    "train, test = data_splits(data,0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8d405a-9163-4cd4-81db-0fe2f1b9c70b",
   "metadata": {},
   "source": [
    "Show random samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff114a68-12e4-49d0-87de-661350d2f650",
   "metadata": {},
   "source": [
    "Create the data loaders for train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19b727ed-e44a-47f0-b743-93c222d3395a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader = create_data_loader(train,test,batch_size=32,cuda_avail=cuda_enabled)\n",
    "\n",
    "# For debugging purposes, I will get the first samples\n",
    "train_features, train_labels = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c5c326-0345-4c60-a1bc-166f0976426b",
   "metadata": {},
   "source": [
    "### 4.3 Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8309d7fc-71fc-46bf-9dca-704eb8eb2cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test the model. This is good to know the output shape of the network\n",
    "model = MovieRest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a5d60052-0d10-48b7-9aed-29032ef428b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MovieRest(\n",
      "  (ResNetBlock): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (4): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (6): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  )\n",
      "  (Classifier): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=128, out_features=51, bias=True)\n",
      "  )\n",
      ")\n",
      "Number of Parameters: 689651\n"
     ]
    }
   ],
   "source": [
    "print_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a201637-d6eb-406e-a531-bd381555acc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# send the model to the GPU\n",
    "if cuda_enabled:\n",
    "    model = model.cuda(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410d59ef-6c4d-4599-afb6-a149a4a77884",
   "metadata": {},
   "source": [
    "### 4.4. Optimizer and loss function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d82cb9b2-0f31-4e4e-820a-9d66fb453544",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam, SGD\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "# defining the optimizer (receives the parameters of the model!)\n",
    "optimizer = Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# defining the loss function, in this caase cross entropy loss (it has softmax embedded!)\n",
    "loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7a7b8ea6-ecb5-4c76-afb3-3a6d7fd19002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# send the loss to the GPU\n",
    "if torch.cuda.is_available():\n",
    "    loss_func = loss_func.cuda(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "939b1d2f-891c-462c-ad05-55d05be97eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(pred,y):\n",
    "    return (pred.argmax(1)==y.argmax(1)).float().mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "61044e77-67d2-4e6a-a468-4a18c1a8add2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model,dataloader):\n",
    "    model.eval()\n",
    "    loss = accu = 0\n",
    "    for X, Y in dataloader: \n",
    "        X=X.cuda(device)\n",
    "        Y=Y.cuda(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            pred = model(X)\n",
    "        \n",
    "            loss += loss_func(pred, Y) * len(X)\n",
    "            accu += accuracy(pred,Y) * len(X)\n",
    "    model.train()\n",
    "    return loss.item()/len(dataloader.dataset), accu/len(dataloader.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926bf5c7-5477-47d8-b5f3-8b632b327f14",
   "metadata": {},
   "source": [
    "### 4.5 Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a40959c4-b804-4111-9a22-cb8613e3b911",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5a9038b0-225a-4803-8101-90e025872e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "epochs = 20\n",
    "\n",
    "def train(model, traindl, valdl, epochs=20, tensorboard=False, printstep=100):\n",
    "\n",
    "    # number of samples in training, TODO what if data augmentation?\n",
    "    size = len(traindl.dataset) \n",
    "\n",
    "    print (f\"number of samples {size}\")\n",
    "    print (f\"number of epochs {epochs}\")\n",
    "\n",
    "    tb_writer = None\n",
    "    if tensorboard:           # create the log dir\n",
    "        tb_writer = SummaryWriter()\n",
    "        \n",
    "    for epoch in range(epochs):\n",
    "        t0 = t1 = time.time()     # our timers\n",
    "        print(f\"epoch: {epoch}\")\n",
    "        loss_train = acc_train = 0\n",
    "        \n",
    "        for batch, (X, Y) in enumerate(traindl):  # for each sample\n",
    "            # send the data to the GPU\n",
    "            X=X.cuda(device)\n",
    "            Y=Y.cuda(device)\n",
    "\n",
    "            # FORWARD            \n",
    "            pred = model(X)           # Compute prediction of the network            \n",
    "            loss = loss_func(pred, Y) # Calculate the loss\n",
    "\n",
    "            # BACKWARD        \n",
    "            loss.backward()        # the backpropagation phase, from loss to all recorded tensors        \n",
    "            optimizer.step()       # one step of the optimizer        \n",
    "            optimizer.zero_grad(set_to_none=True)  # gradients are accumulated in PyTorch, need to zero them.        \n",
    "            #for param in model.parameters():  # this loop is similar to using set_to_none=True in zero_grad\n",
    "            #    param.grad = None\n",
    "            \n",
    "            loss, current = loss.item(), batch * len(X) # calculate loss and acc\n",
    "            acc = accuracy(pred,Y)\n",
    "\n",
    "            if tensorboard:  # write to tensorboard\n",
    "                tb_writer.add_scalar(\"Loss/train\", loss, current+epoch*size)\n",
    "                tb_writer.add_scalar(\"Accuracy/train\", acc, current+epoch*size)\n",
    "\n",
    "            if (printstep > 0 and batch > 0 and batch % printstep == 0):                    \n",
    "                print(f\"loss: {loss:>7f} accuracy: {acc:>7f}  [{current:>5d}/{size:>5d}/{epoch:>2d}] | elapsed time: {time.time() - t1:>4f} s\")\n",
    "                t1 = time.time()  # timer for batches\n",
    "            \n",
    "            loss_train += loss*len(X)\n",
    "            acc_train += acc*len(X)\n",
    "\n",
    "\n",
    "        loss_train = loss_train / size  # mean of loss and acc for train\n",
    "        acc_train  = acc_train / size\n",
    "        print(f\"Train: loss: {loss_train:>7f} accuracy: {acc_train:>7f} | elapsed time: {time.time() - t0:>4f} s\")          \n",
    "        t0 = time.time()\n",
    "        \n",
    "        loss, acc = validation(model,valdl)  # validation phase\n",
    "        print(f\"Validation: loss: {loss:>7f} accuracy: {acc:>7f} | elapsed time: {time.time() - t0:>4f} s\")  \n",
    "\n",
    "        if tensorboard:   # write validation to tensorboard\n",
    "            tb_writer.add_scalar(\"Loss/val\", loss, epoch)\n",
    "            tb_writer.add_scalar(\"Accuracy/val\", acc, epoch)\n",
    "    \n",
    "    if tensorboard:\n",
    "        tb_writer.flush()\n",
    "        tb_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "79510f64-358b-478f-bd63-c8897a8a3f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of samples 27731\n",
      "number of epochs 20\n",
      "epoch: 0\n",
      "loss: 3.032784 accuracy: 0.218750  [ 6400/27731/ 0] | elapsed time: 14.326731 s\n",
      "loss: 2.861155 accuracy: 0.218750  [12800/27731/ 0] | elapsed time: 14.259520 s\n",
      "loss: 2.661568 accuracy: 0.343750  [19200/27731/ 0] | elapsed time: 14.898455 s\n",
      "loss: 2.278927 accuracy: 0.531250  [25600/27731/ 0] | elapsed time: 14.614145 s\n",
      "Train: loss: 2.858359 accuracy: 0.248062 | elapsed time: 63.317518 s\n",
      "Validation: loss: 3.797125 accuracy: 0.162844 | elapsed time: 12.037775 s\n",
      "epoch: 1\n",
      "loss: 2.533508 accuracy: 0.281250  [ 6400/27731/ 1] | elapsed time: 15.164652 s\n",
      "loss: 2.158029 accuracy: 0.406250  [12800/27731/ 1] | elapsed time: 17.448061 s\n",
      "loss: 2.559329 accuracy: 0.312500  [19200/27731/ 1] | elapsed time: 14.175508 s\n",
      "loss: 1.995681 accuracy: 0.468750  [25600/27731/ 1] | elapsed time: 15.108387 s\n",
      "Train: loss: 2.379677 accuracy: 0.360788 | elapsed time: 66.501022 s\n",
      "Validation: loss: 2.301863 accuracy: 0.377614 | elapsed time: 12.235838 s\n",
      "epoch: 2\n",
      "loss: 1.948197 accuracy: 0.375000  [ 6400/27731/ 2] | elapsed time: 15.376106 s\n",
      "loss: 1.600239 accuracy: 0.437500  [12800/27731/ 2] | elapsed time: 15.166803 s\n",
      "loss: 2.232679 accuracy: 0.375000  [19200/27731/ 2] | elapsed time: 16.182803 s\n",
      "loss: 2.470525 accuracy: 0.281250  [25600/27731/ 2] | elapsed time: 16.482551 s\n",
      "Train: loss: 2.126814 accuracy: 0.415167 | elapsed time: 67.847085 s\n",
      "Validation: loss: 2.454544 accuracy: 0.347757 | elapsed time: 11.761660 s\n",
      "epoch: 3\n",
      "loss: 2.233386 accuracy: 0.375000  [ 6400/27731/ 3] | elapsed time: 15.124195 s\n",
      "loss: 2.055170 accuracy: 0.343750  [12800/27731/ 3] | elapsed time: 14.929402 s\n",
      "loss: 2.152731 accuracy: 0.406250  [19200/27731/ 3] | elapsed time: 14.672100 s\n",
      "loss: 1.618296 accuracy: 0.625000  [25600/27731/ 3] | elapsed time: 15.524452 s\n",
      "Train: loss: 1.948110 accuracy: 0.458728 | elapsed time: 66.098100 s\n",
      "Validation: loss: 2.143907 accuracy: 0.427232 | elapsed time: 15.308983 s\n",
      "epoch: 4\n",
      "loss: 1.962950 accuracy: 0.437500  [ 6400/27731/ 4] | elapsed time: 8.868439 s\n",
      "loss: 1.699186 accuracy: 0.500000  [12800/27731/ 4] | elapsed time: 8.196621 s\n",
      "loss: 1.528668 accuracy: 0.593750  [19200/27731/ 4] | elapsed time: 8.661990 s\n",
      "loss: 1.650933 accuracy: 0.593750  [25600/27731/ 4] | elapsed time: 8.164017 s\n",
      "Train: loss: 1.814461 accuracy: 0.496087 | elapsed time: 36.772487 s\n",
      "Validation: loss: 2.104480 accuracy: 0.429973 | elapsed time: 7.859327 s\n",
      "epoch: 5\n",
      "loss: 1.581207 accuracy: 0.562500  [ 6400/27731/ 5] | elapsed time: 8.703101 s\n",
      "loss: 1.513277 accuracy: 0.593750  [12800/27731/ 5] | elapsed time: 8.054816 s\n",
      "loss: 1.623880 accuracy: 0.593750  [19200/27731/ 5] | elapsed time: 8.473467 s\n",
      "loss: 1.208666 accuracy: 0.718750  [25600/27731/ 5] | elapsed time: 8.196354 s\n",
      "Train: loss: 1.710489 accuracy: 0.519347 | elapsed time: 36.113631 s\n",
      "Validation: loss: 3.007027 accuracy: 0.340545 | elapsed time: 7.823771 s\n",
      "epoch: 6\n",
      "loss: 1.908392 accuracy: 0.468750  [ 6400/27731/ 6] | elapsed time: 8.654337 s\n",
      "loss: 1.320059 accuracy: 0.562500  [12800/27731/ 6] | elapsed time: 8.138215 s\n",
      "loss: 1.386356 accuracy: 0.593750  [19200/27731/ 6] | elapsed time: 8.606255 s\n",
      "loss: 1.419129 accuracy: 0.562500  [25600/27731/ 6] | elapsed time: 8.117037 s\n",
      "Train: loss: 1.623831 accuracy: 0.539000 | elapsed time: 36.502021 s\n",
      "Validation: loss: 1.888320 accuracy: 0.483196 | elapsed time: 7.856889 s\n",
      "epoch: 7\n",
      "loss: 1.108199 accuracy: 0.718750  [ 6400/27731/ 7] | elapsed time: 8.722570 s\n",
      "loss: 1.544869 accuracy: 0.562500  [12800/27731/ 7] | elapsed time: 8.746641 s\n",
      "loss: 1.281966 accuracy: 0.593750  [19200/27731/ 7] | elapsed time: 7.885253 s\n",
      "loss: 1.629722 accuracy: 0.562500  [25600/27731/ 7] | elapsed time: 8.601650 s\n",
      "Train: loss: 1.535132 accuracy: 0.564170 | elapsed time: 36.585412 s\n",
      "Validation: loss: 2.643432 accuracy: 0.340978 | elapsed time: 7.899527 s\n",
      "epoch: 8\n",
      "loss: 1.393671 accuracy: 0.656250  [ 6400/27731/ 8] | elapsed time: 8.907515 s\n",
      "loss: 1.619061 accuracy: 0.562500  [12800/27731/ 8] | elapsed time: 8.080355 s\n",
      "loss: 1.167889 accuracy: 0.593750  [19200/27731/ 8] | elapsed time: 8.565808 s\n",
      "loss: 1.977890 accuracy: 0.500000  [25600/27731/ 8] | elapsed time: 8.063726 s\n",
      "Train: loss: 1.464745 accuracy: 0.578630 | elapsed time: 36.317739 s\n",
      "Validation: loss: 1.782039 accuracy: 0.515073 | elapsed time: 7.900002 s\n",
      "epoch: 9\n",
      "loss: 1.218870 accuracy: 0.687500  [ 6400/27731/ 9] | elapsed time: 8.660642 s\n",
      "loss: 1.162608 accuracy: 0.593750  [12800/27731/ 9] | elapsed time: 8.734807 s\n",
      "loss: 0.900278 accuracy: 0.656250  [19200/27731/ 9] | elapsed time: 8.264009 s\n",
      "loss: 1.282315 accuracy: 0.625000  [25600/27731/ 9] | elapsed time: 8.540240 s\n",
      "Train: loss: 1.391999 accuracy: 0.601781 | elapsed time: 36.954894 s\n",
      "Validation: loss: 1.823623 accuracy: 0.498630 | elapsed time: 7.845770 s\n",
      "epoch: 10\n",
      "loss: 1.640890 accuracy: 0.625000  [ 6400/27731/10] | elapsed time: 8.515628 s\n",
      "loss: 1.052315 accuracy: 0.750000  [12800/27731/10] | elapsed time: 8.320801 s\n",
      "loss: 1.396454 accuracy: 0.687500  [19200/27731/10] | elapsed time: 8.332736 s\n",
      "loss: 1.964498 accuracy: 0.468750  [25600/27731/10] | elapsed time: 8.511521 s\n",
      "Train: loss: 1.328675 accuracy: 0.613718 | elapsed time: 36.425454 s\n",
      "Validation: loss: 1.858255 accuracy: 0.493870 | elapsed time: 7.849537 s\n",
      "epoch: 11\n",
      "loss: 1.654648 accuracy: 0.562500  [ 6400/27731/11] | elapsed time: 8.655771 s\n",
      "loss: 1.170380 accuracy: 0.656250  [12800/27731/11] | elapsed time: 8.544833 s\n",
      "loss: 0.903214 accuracy: 0.781250  [19200/27731/11] | elapsed time: 8.703454 s\n",
      "loss: 1.265127 accuracy: 0.593750  [25600/27731/11] | elapsed time: 7.765357 s\n",
      "Train: loss: 1.262088 accuracy: 0.634056 | elapsed time: 36.513624 s\n",
      "Validation: loss: 1.804840 accuracy: 0.510169 | elapsed time: 7.799512 s\n",
      "epoch: 12\n",
      "loss: 1.142153 accuracy: 0.750000  [ 6400/27731/12] | elapsed time: 8.609650 s\n",
      "loss: 1.387558 accuracy: 0.531250  [12800/27731/12] | elapsed time: 8.190246 s\n",
      "loss: 1.543506 accuracy: 0.562500  [19200/27731/12] | elapsed time: 8.923407 s\n",
      "loss: 1.440471 accuracy: 0.593750  [25600/27731/12] | elapsed time: 8.143816 s\n",
      "Train: loss: 1.213511 accuracy: 0.645307 | elapsed time: 36.672928 s\n",
      "Validation: loss: 1.640447 accuracy: 0.542766 | elapsed time: 7.822910 s\n",
      "epoch: 13\n",
      "loss: 1.147672 accuracy: 0.625000  [ 6400/27731/13] | elapsed time: 8.403844 s\n",
      "loss: 1.241178 accuracy: 0.718750  [12800/27731/13] | elapsed time: 8.888931 s\n",
      "loss: 0.797390 accuracy: 0.687500  [19200/27731/13] | elapsed time: 8.105740 s\n",
      "loss: 1.035853 accuracy: 0.656250  [25600/27731/13] | elapsed time: 8.258898 s\n",
      "Train: loss: 1.158350 accuracy: 0.661390 | elapsed time: 36.775730 s\n",
      "Validation: loss: 1.740283 accuracy: 0.537430 | elapsed time: 7.875789 s\n",
      "epoch: 14\n",
      "loss: 0.716671 accuracy: 0.812500  [ 6400/27731/14] | elapsed time: 8.866809 s\n",
      "loss: 0.962919 accuracy: 0.781250  [12800/27731/14] | elapsed time: 8.290654 s\n",
      "loss: 0.918356 accuracy: 0.687500  [19200/27731/14] | elapsed time: 8.487579 s\n",
      "loss: 1.294962 accuracy: 0.687500  [25600/27731/14] | elapsed time: 8.218109 s\n",
      "Train: loss: 1.102840 accuracy: 0.676427 | elapsed time: 36.583910 s\n",
      "Validation: loss: 1.709555 accuracy: 0.540603 | elapsed time: 7.915000 s\n",
      "epoch: 15\n",
      "loss: 1.052733 accuracy: 0.593750  [ 6400/27731/15] | elapsed time: 8.629760 s\n",
      "loss: 0.819841 accuracy: 0.656250  [12800/27731/15] | elapsed time: 8.400864 s\n",
      "loss: 1.279336 accuracy: 0.656250  [19200/27731/15] | elapsed time: 8.059797 s\n",
      "loss: 1.082192 accuracy: 0.562500  [25600/27731/15] | elapsed time: 8.710502 s\n",
      "Train: loss: 1.041208 accuracy: 0.689589 | elapsed time: 36.730777 s\n",
      "Validation: loss: 1.469664 accuracy: 0.585749 | elapsed time: 7.804103 s\n",
      "epoch: 16\n",
      "loss: 1.046729 accuracy: 0.718750  [ 6400/27731/16] | elapsed time: 8.647756 s\n",
      "loss: 0.852694 accuracy: 0.750000  [12800/27731/16] | elapsed time: 8.067573 s\n",
      "loss: 0.816777 accuracy: 0.812500  [19200/27731/16] | elapsed time: 8.639113 s\n",
      "loss: 0.870990 accuracy: 0.750000  [25600/27731/16] | elapsed time: 8.516606 s\n",
      "Train: loss: 0.993856 accuracy: 0.701597 | elapsed time: 36.564711 s\n",
      "Validation: loss: 1.430842 accuracy: 0.602914 | elapsed time: 7.841327 s\n",
      "epoch: 17\n",
      "loss: 0.604910 accuracy: 0.750000  [ 6400/27731/17] | elapsed time: 8.499017 s\n",
      "loss: 0.950382 accuracy: 0.687500  [12800/27731/17] | elapsed time: 8.322111 s\n",
      "loss: 1.128292 accuracy: 0.625000  [19200/27731/17] | elapsed time: 8.189396 s\n",
      "loss: 0.600144 accuracy: 0.843750  [25600/27731/17] | elapsed time: 8.510878 s\n",
      "Train: loss: 0.941019 accuracy: 0.721142 | elapsed time: 36.372950 s\n",
      "Validation: loss: 1.501382 accuracy: 0.589932 | elapsed time: 7.844572 s\n",
      "epoch: 18\n",
      "loss: 1.152235 accuracy: 0.656250  [ 6400/27731/18] | elapsed time: 9.114779 s\n",
      "loss: 0.900101 accuracy: 0.750000  [12800/27731/18] | elapsed time: 7.953023 s\n",
      "loss: 0.859661 accuracy: 0.750000  [19200/27731/18] | elapsed time: 8.443836 s\n",
      "loss: 0.828777 accuracy: 0.750000  [25600/27731/18] | elapsed time: 8.481463 s\n",
      "Train: loss: 0.881765 accuracy: 0.733583 | elapsed time: 36.659557 s\n",
      "Validation: loss: 1.696969 accuracy: 0.561950 | elapsed time: 7.877402 s\n",
      "epoch: 19\n",
      "loss: 0.840973 accuracy: 0.812500  [ 6400/27731/19] | elapsed time: 8.486806 s\n",
      "loss: 0.560535 accuracy: 0.843750  [12800/27731/19] | elapsed time: 8.558056 s\n",
      "loss: 1.127434 accuracy: 0.656250  [19200/27731/19] | elapsed time: 8.066977 s\n",
      "loss: 0.913415 accuracy: 0.781250  [25600/27731/19] | elapsed time: 8.451910 s\n",
      "Train: loss: 0.832151 accuracy: 0.748729 | elapsed time: 36.259473 s\n",
      "Validation: loss: 2.590923 accuracy: 0.485216 | elapsed time: 7.869424 s\n"
     ]
    }
   ],
   "source": [
    "train(model,train_loader,test_loader,printstep=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43224253-3917-46f6-b286-bd8aee556097",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
