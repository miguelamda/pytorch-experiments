{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e405ba2-709c-4827-bca7-e698dd54b21b",
   "metadata": {},
   "source": [
    "# Reproducing Movie Tag classification model in PyTorch\n",
    "\n",
    "This notebook is my \"getting started\" notebook for PyTorch, and I will work with our dataset on Movie Tag extraction. https://doi.org/10.1109/ACCESS.2019.2963535\n",
    "\n",
    "## 1 Load the dataset\n",
    "\n",
    "We can load datasets from folders with ImageFolder. Later, we can split the dataset in test, val, train with random_split.\n",
    "\n",
    "### 1.1 Auxiliary functions for dataset\n",
    "\n",
    "Let's define a function to load the dataset:                                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4dd45a01-7715-4b1d-b82c-35efad749484",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/miguel/.local/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "\n",
    "# what: loads the movie tag dataset from a folder, and a dictionary with the label names\n",
    "# input: folder, image size, and verbosity\n",
    "# return: data object\n",
    "# example: data = load_movie_dataset('./data/Movie',[128,128])\n",
    "def load_movietag_dataset(folder,im_size=[128,128],verbose=True):\n",
    "    data = datasets.ImageFolder(\n",
    "         folder,\n",
    "         transform=transforms.Compose([transforms.ToTensor(),transforms.Resize(im_size)]),\n",
    "         target_transform=transforms.Lambda(lambda y: torch.zeros(51, dtype=torch.float).scatter_(0, torch.tensor(y), value=1))\n",
    "         )\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Loaded {len(data)} samples\")\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5d7fd9-ecc0-4a92-a01d-06270ed5f34a",
   "metadata": {},
   "source": [
    "Now let's define a function to do the splits of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adfacbf4-299f-46ee-adb5-6047fc145ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what: split the dataset in train test\n",
    "# input: dataset object, the percentage for train, verbosity\n",
    "# return: data objects for train an val\n",
    "# example: train, val = data_splits(data,0.8)\n",
    "def data_splits(dataset,tr_percent=0.8,verbose=True):\n",
    "    total_size = len(data)\n",
    "    train_size = int(np.floor(tr_percent*total_size))\n",
    "    test_size  = total_size-train_size\n",
    "    \n",
    "    # we can split the dataset randomnly like this\n",
    "    train, test = torch.utils.data.random_split(data, [train_size, test_size])\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Splitted the dataset with {len(data)} samples. Train: {len(train)}, Test: {len(test)}\")\n",
    "    \n",
    "    return train, test\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c147e53-50db-4958-a611-482181bab9b5",
   "metadata": {},
   "source": [
    "One function to check the status of the dataset (randomnly show images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66dac60c-56ba-4579-ad65-4950d03d8afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def print_random_samples(data):\n",
    "    figure = plt.figure(figsize=(8, 8))\n",
    "    cols, rows = 3, 3\n",
    "    for i in range(1, cols * rows + 1):\n",
    "        sample_idx = torch.randint(len(data), size=(1,)).item() # random number, get item because it's a random tensor\n",
    "        img, label = data[sample_idx]\n",
    "        figure.add_subplot(rows, cols, i)\n",
    "        plt.title(data.classes[torch.argmax(label).item()])\n",
    "        plt.axis(\"off\")\n",
    "        plt.imshow(transforms.ToPILImage()(img)) #, cmap=\"rgb\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf81c1d2-674f-4918-b021-3fca161eb6d4",
   "metadata": {},
   "source": [
    "The following function creates the data loaders (the iterators over the dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c50d106b-b999-4fcb-b6f5-8aeffb1fd023",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def create_data_loader(train,test,batch_size=32,cuda_avail=False):\n",
    "    train_dataloader = DataLoader(train, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=cuda_avail)\n",
    "    test_dataloader = DataLoader(test, batch_size=batch_size*2, num_workers=8, pin_memory=cuda_avail) \n",
    "    return train_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624b8c8a-0896-45b2-acea-fddf95936dcb",
   "metadata": {},
   "source": [
    "### 1.2 Auxiliary functions for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e5110d5-ce9a-4796-ba89-b38241a6442a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "def print_model(model):\n",
    "    print(model)\n",
    "    print(f\"Number of Parameters: {count_parameters(model)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6452e33-fbf9-4bf0-ac83-e0ae0abada85",
   "metadata": {},
   "source": [
    "## 2. Quick look to the dataset\n",
    "\n",
    "We will load the dataset and print a couple of random samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "435c7e43-8201-4cb1-800f-5d55fab4b646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 34664 samples\n"
     ]
    }
   ],
   "source": [
    "data = load_movietag_dataset('./data/Movie')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffea6f12-b1db-447c-87de-a9d920fc78f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print_random_samples(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02ad901-dbc6-4637-80b9-279cf68b9ffe",
   "metadata": {},
   "source": [
    "## 3. Model definition\n",
    "\n",
    "Next, we define the model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68ba861f-217f-4142-8b4d-f8818ed73180",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "resnet18 = models.resnet18(pretrained=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1f37d5f8-c190-4891-9659-63b86cd92096",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class MovieRest(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MovieRest, self).__init__()      ## required!  \n",
    "        self.ResNetBlock = nn.Sequential(\n",
    "            resnet18.conv1,\n",
    "            resnet18.bn1,\n",
    "            resnet18.relu,\n",
    "            resnet18.maxpool,\n",
    "            resnet18.layer1,\n",
    "            resnet18.layer2,\n",
    "            nn.AdaptiveAvgPool2d(output_size=(1, 1))\n",
    "        )\n",
    "        self.Classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=128, out_features=51, bias=True)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        convX = self.ResNetBlock(x)\n",
    "        return self.Classifier(convX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a3ce130c-fa51-4959-9d97-756dc7d0a9db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 51])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelRest = MovieRest()\n",
    "\n",
    "#modelRest(train_features).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f8c1eaea-f5ba-4efe-8420-b183fbb2c259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MovieRest(\n",
      "  (ResNetBlock): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (4): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (6): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  )\n",
      "  (Classifier): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=128, out_features=51, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#print(resnet18)\n",
    "print(modelRest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d95cd6b-c0ed-4394-831d-f37cbdedf48e",
   "metadata": {},
   "source": [
    "## 4. Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcce6af-dd47-4dc4-962f-a52537ea5679",
   "metadata": {},
   "source": [
    "### 4.1. Check CUDA installation\n",
    "\n",
    "Let's check if we have CUDA on the server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4226e872-1e73-484a-9bef-b5cb22671021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce RTX 2080'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuda_enabled = torch.cuda.is_available()\n",
    "\n",
    "device = \"cuda\" if cuda_enabled else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "torch.cuda.get_device_name(torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad1fa02-5498-478c-9128-c40587880583",
   "metadata": {},
   "source": [
    "### 4.2. Load the dataset and create data loaders\n",
    "Load the dataset and split in test and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1d5eb2e7-47a3-48f2-a4b9-82a7ac933161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 34664 samples\n",
      "Splitted the dataset with 34664 samples. Train: 27731, Test: 6933\n"
     ]
    }
   ],
   "source": [
    "image_res=[128,128]  # input resolution to the model\n",
    "\n",
    "# load the dataset\n",
    "data = load_movietag_dataset('./data/Movie',image_res)\n",
    "\n",
    "# split the data\n",
    "train, test = data_splits(data,0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8d405a-9163-4cd4-81db-0fe2f1b9c70b",
   "metadata": {},
   "source": [
    "Show random samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff114a68-12e4-49d0-87de-661350d2f650",
   "metadata": {},
   "source": [
    "Create the data loaders for train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "19b727ed-e44a-47f0-b743-93c222d3395a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader = create_data_loader(train,test,batch_size=32,cuda_avail=cuda_enabled)\n",
    "\n",
    "# For debugging purposes, I will get the first samples\n",
    "train_features, train_labels = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c5c326-0345-4c60-a1bc-166f0976426b",
   "metadata": {},
   "source": [
    "### 4.3 Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8309d7fc-71fc-46bf-9dca-704eb8eb2cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test the model. This is good to know the output shape of the network\n",
    "model = MovieRest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a5d60052-0d10-48b7-9aed-29032ef428b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MovieRest(\n",
      "  (ResNetBlock): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (4): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (6): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  )\n",
      "  (Classifier): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=128, out_features=51, bias=True)\n",
      "  )\n",
      ")\n",
      "Number of Parameters: 689651\n"
     ]
    }
   ],
   "source": [
    "print_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0a201637-d6eb-406e-a531-bd381555acc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# send the model to the GPU\n",
    "if cuda_enabled:\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410d59ef-6c4d-4599-afb6-a149a4a77884",
   "metadata": {},
   "source": [
    "### 4.4. Optimizer and loss function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d82cb9b2-0f31-4e4e-820a-9d66fb453544",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam, SGD\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "# defining the optimizer (receives the parameters of the model!)\n",
    "optimizer = Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# defining the loss function, in this caase cross entropy loss (it has softmax embedded!)\n",
    "loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7a7b8ea6-ecb5-4c76-afb3-3a6d7fd19002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# send the loss to the GPU\n",
    "if torch.cuda.is_available():\n",
    "    loss_func = loss_func.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "939b1d2f-891c-462c-ad05-55d05be97eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(pred,y):\n",
    "    return (pred.argmax(1)==y.argmax(1)).float().mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "61044e77-67d2-4e6a-a468-4a18c1a8add2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model,dataloader):\n",
    "    model.eval()\n",
    "    loss = accu = 0\n",
    "    for X, Y in dataloader: \n",
    "        X=X.cuda()\n",
    "        Y=Y.cuda()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            pred = model(X)\n",
    "        \n",
    "            loss += loss_func(pred, Y)\n",
    "            accu += accuracy(pred,Y)\n",
    "    model.train()\n",
    "    return loss.item()/len(dataloader), accu/len(dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926bf5c7-5477-47d8-b5f3-8b632b327f14",
   "metadata": {},
   "source": [
    "### 4.5 Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a40959c4-b804-4111-9a22-cb8613e3b911",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5a9038b0-225a-4803-8101-90e025872e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "epochs = 20\n",
    "\n",
    "def train(model, traindl, valdl, epochs=20, tensorboard=False, printstep=100):\n",
    "\n",
    "    # number of samples in training, TODO what if data augmentation?\n",
    "    size = len(traindl.dataset) \n",
    "\n",
    "    print (f\"number of samples {size}\")\n",
    "    print (f\"number of epochs {epochs}\")\n",
    "\n",
    "    tb_writer = None\n",
    "    if tensorboard:           # create the log dir\n",
    "        tb_writer = SummaryWriter()\n",
    "        \n",
    "    t0 = t1 = time.time()     # our timers\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"epoch: {epoch}\")\n",
    "        loss_train = acc_train = 0\n",
    "        \n",
    "        for batch, (X, Y) in enumerate(traindl):  # for each sample\n",
    "            # send the data to the GPU\n",
    "            X=X.cuda()\n",
    "            Y=Y.cuda()\n",
    "\n",
    "            # FORWARD            \n",
    "            pred = model(X)           # Compute prediction of the network            \n",
    "            loss = loss_func(pred, Y) # Calculate the loss\n",
    "\n",
    "            # BACKWARD        \n",
    "            loss.backward()        # the backpropagation phase, from loss to all recorded tensors        \n",
    "            optimizer.step()       # one step of the optimizer        \n",
    "            optimizer.zero_grad(set_to_none=True)  # gradients are accumulated in PyTorch, need to zero them.        \n",
    "            #for param in model.parameters():  # this loop is similar to using set_to_none=True in zero_grad\n",
    "            #    param.grad = None\n",
    "            \n",
    "            loss, current = loss.item(), batch * len(X) # calculate loss and acc\n",
    "            acc = accuracy(pred,Y)\n",
    "\n",
    "            if tensorboard:  # write to tensorboard\n",
    "                tb_writer.add_scalar(\"Loss/train\", loss, current+epoch*size)\n",
    "                tb_writer.add_scalar(\"Accuracy/train\", acc, current+epoch*size)\n",
    "\n",
    "            if (printstep > 0 and batch > 0 and batch % printstep == 0):                    \n",
    "                print(f\"loss: {loss:>7f} accuracy: {acc:>7f}  [{current:>5d}/{size:>5d}/{epoch:>2d}] | elapsed time: {time.time() - t1:>4f} s\")\n",
    "                t1 = time.time()  # timer for batches\n",
    "            \n",
    "            loss_train += loss\n",
    "            acc_train += acc\n",
    "\n",
    "\n",
    "        loss_train = loss_train / len(traindl)  # mean of loss and acc for train\n",
    "        acc_train  = acc_train / len(traindl)\n",
    "        print(f\"Train: loss: {loss_train:>7f} accuracy: {acc_train:>7f} | elapsed time: {time.time() - t0:>4f} s\")          \n",
    "        t0 = time.time()\n",
    "        \n",
    "        loss, acc = validation(model,valdl)  # validation phase\n",
    "        print(f\"Validation: loss: {loss:>7f} accuracy: {acc:>7f} | elapsed time: {time.time() - t0:>4f} s\")  \n",
    "\n",
    "        if tensorboard:   # write validation to tensorboard\n",
    "            tb_writer.add_scalar(\"Loss/val\", loss, epoch)\n",
    "            tb_writer.add_scalar(\"Accuracy/val\", acc, epoch)\n",
    "        \n",
    "        t0 = time.time()  # timer for epochs and validation\n",
    "    \n",
    "    if tensorboard:\n",
    "        tb_writer.flush()\n",
    "        tb_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "79510f64-358b-478f-bd63-c8897a8a3f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of samples 27731\n",
      "number of epochs 20\n",
      "epoch: 0\n",
      "loss: 3.171304 accuracy: 0.125000  [ 6400/27731/ 0] | elapsed time: 8.922879 s\n",
      "loss: 2.896651 accuracy: 0.187500  [12800/27731/ 0] | elapsed time: 8.292078 s\n",
      "loss: 2.205733 accuracy: 0.406250  [19200/27731/ 0] | elapsed time: 8.476676 s\n",
      "loss: 2.378985 accuracy: 0.312500  [25600/27731/ 0] | elapsed time: 8.449183 s\n",
      "Train: loss: 2.829907 accuracy: 0.256767 | elapsed time: 36.820792 s\n",
      "Validation: loss: 2.885496 accuracy: 0.282602 | elapsed time: 8.064767 s\n",
      "epoch: 1\n",
      "loss: 2.067702 accuracy: 0.406250  [ 6400/27731/ 1] | elapsed time: 19.374641 s\n",
      "loss: 2.611017 accuracy: 0.406250  [12800/27731/ 1] | elapsed time: 8.188091 s\n",
      "loss: 1.828427 accuracy: 0.562500  [19200/27731/ 1] | elapsed time: 8.581048 s\n",
      "loss: 2.057549 accuracy: 0.468750  [25600/27731/ 1] | elapsed time: 8.655234 s\n",
      "Train: loss: 2.343051 accuracy: 0.366932 | elapsed time: 36.936126 s\n",
      "Validation: loss: 2.671601 accuracy: 0.306513 | elapsed time: 8.028321 s\n",
      "epoch: 2\n",
      "loss: 2.460915 accuracy: 0.406250  [ 6400/27731/ 2] | elapsed time: 19.808651 s\n",
      "loss: 1.947789 accuracy: 0.406250  [12800/27731/ 2] | elapsed time: 8.263616 s\n",
      "loss: 2.338263 accuracy: 0.343750  [19200/27731/ 2] | elapsed time: 7.971387 s\n",
      "loss: 1.846572 accuracy: 0.437500  [25600/27731/ 2] | elapsed time: 8.268152 s\n",
      "Train: loss: 2.098104 accuracy: 0.425640 | elapsed time: 36.357571 s\n",
      "Validation: loss: 2.148859 accuracy: 0.416346 | elapsed time: 8.063222 s\n",
      "epoch: 3\n",
      "loss: 1.590635 accuracy: 0.531250  [ 6400/27731/ 3] | elapsed time: 19.761809 s\n",
      "loss: 1.428897 accuracy: 0.531250  [12800/27731/ 3] | elapsed time: 8.417640 s\n",
      "loss: 1.809960 accuracy: 0.625000  [19200/27731/ 3] | elapsed time: 8.468631 s\n",
      "loss: 2.021194 accuracy: 0.437500  [25600/27731/ 3] | elapsed time: 7.974224 s\n",
      "Train: loss: 1.926433 accuracy: 0.464440 | elapsed time: 36.304738 s\n",
      "Validation: loss: 2.037131 accuracy: 0.437568 | elapsed time: 8.029868 s\n",
      "epoch: 4\n",
      "loss: 1.805117 accuracy: 0.531250  [ 6400/27731/ 4] | elapsed time: 19.478900 s\n",
      "loss: 2.201782 accuracy: 0.437500  [12800/27731/ 4] | elapsed time: 8.260554 s\n",
      "loss: 1.712014 accuracy: 0.468750  [19200/27731/ 4] | elapsed time: 8.607824 s\n",
      "loss: 1.520819 accuracy: 0.531250  [25600/27731/ 4] | elapsed time: 8.001767 s\n",
      "Train: loss: 1.788883 accuracy: 0.501387 | elapsed time: 36.521080 s\n",
      "Validation: loss: 2.436940 accuracy: 0.386516 | elapsed time: 8.091677 s\n",
      "epoch: 5\n",
      "loss: 1.892794 accuracy: 0.468750  [ 6400/27731/ 5] | elapsed time: 19.488610 s\n",
      "loss: 1.677048 accuracy: 0.531250  [12800/27731/ 5] | elapsed time: 8.206922 s\n",
      "loss: 1.565399 accuracy: 0.531250  [19200/27731/ 5] | elapsed time: 8.747034 s\n",
      "loss: 1.842624 accuracy: 0.406250  [25600/27731/ 5] | elapsed time: 8.211291 s\n",
      "Train: loss: 1.682498 accuracy: 0.525198 | elapsed time: 36.535670 s\n",
      "Validation: loss: 2.074990 accuracy: 0.436838 | elapsed time: 8.058966 s\n",
      "epoch: 6\n",
      "loss: 1.307819 accuracy: 0.656250  [ 6400/27731/ 6] | elapsed time: 19.746995 s\n",
      "loss: 1.286926 accuracy: 0.593750  [12800/27731/ 6] | elapsed time: 8.606272 s\n",
      "loss: 1.654246 accuracy: 0.468750  [19200/27731/ 6] | elapsed time: 8.701902 s\n",
      "loss: 1.712968 accuracy: 0.531250  [25600/27731/ 6] | elapsed time: 8.179112 s\n",
      "Train: loss: 1.581783 accuracy: 0.554386 | elapsed time: 36.894803 s\n",
      "Validation: loss: 2.075574 accuracy: 0.450183 | elapsed time: 8.085029 s\n",
      "epoch: 7\n",
      "loss: 1.771023 accuracy: 0.531250  [ 6400/27731/ 7] | elapsed time: 19.325966 s\n",
      "loss: 1.778469 accuracy: 0.562500  [12800/27731/ 7] | elapsed time: 8.473043 s\n",
      "loss: 1.765437 accuracy: 0.500000  [19200/27731/ 7] | elapsed time: 8.577001 s\n",
      "loss: 1.395900 accuracy: 0.625000  [25600/27731/ 7] | elapsed time: 8.318855 s\n",
      "Train: loss: 1.502439 accuracy: 0.569174 | elapsed time: 36.688181 s\n",
      "Validation: loss: 2.036270 accuracy: 0.461077 | elapsed time: 8.034089 s\n",
      "epoch: 8\n",
      "loss: 1.433280 accuracy: 0.593750  [ 6400/27731/ 8] | elapsed time: 19.184268 s\n",
      "loss: 1.441528 accuracy: 0.625000  [12800/27731/ 8] | elapsed time: 8.477839 s\n",
      "loss: 1.457608 accuracy: 0.625000  [19200/27731/ 8] | elapsed time: 8.335916 s\n",
      "loss: 1.274816 accuracy: 0.656250  [25600/27731/ 8] | elapsed time: 8.308373 s\n",
      "Train: loss: 1.423463 accuracy: 0.591221 | elapsed time: 36.345402 s\n",
      "Validation: loss: 1.775868 accuracy: 0.517843 | elapsed time: 8.056393 s\n",
      "epoch: 9\n",
      "loss: 1.357312 accuracy: 0.562500  [ 6400/27731/ 9] | elapsed time: 19.472662 s\n",
      "loss: 1.498322 accuracy: 0.656250  [12800/27731/ 9] | elapsed time: 8.931488 s\n",
      "loss: 1.677951 accuracy: 0.437500  [19200/27731/ 9] | elapsed time: 8.229089 s\n",
      "loss: 1.726684 accuracy: 0.562500  [25600/27731/ 9] | elapsed time: 8.449632 s\n",
      "Train: loss: 1.354312 accuracy: 0.608198 | elapsed time: 36.894333 s\n",
      "Validation: loss: 1.716625 accuracy: 0.531625 | elapsed time: 8.034963 s\n",
      "epoch: 10\n",
      "loss: 1.448023 accuracy: 0.625000  [ 6400/27731/10] | elapsed time: 19.760856 s\n",
      "loss: 1.143983 accuracy: 0.656250  [12800/27731/10] | elapsed time: 8.217519 s\n",
      "loss: 2.021063 accuracy: 0.406250  [19200/27731/10] | elapsed time: 8.193542 s\n",
      "loss: 1.174696 accuracy: 0.656250  [25600/27731/10] | elapsed time: 8.978708 s\n",
      "Train: loss: 1.288064 accuracy: 0.626544 | elapsed time: 37.194791 s\n",
      "Validation: loss: 1.684175 accuracy: 0.538076 | elapsed time: 8.096039 s\n",
      "epoch: 11\n",
      "loss: 1.108523 accuracy: 0.687500  [ 6400/27731/11] | elapsed time: 19.788244 s\n",
      "loss: 1.434919 accuracy: 0.562500  [12800/27731/11] | elapsed time: 8.483735 s\n",
      "loss: 1.039996 accuracy: 0.750000  [19200/27731/11] | elapsed time: 8.376115 s\n",
      "loss: 1.837228 accuracy: 0.468750  [25600/27731/11] | elapsed time: 8.327295 s\n",
      "Train: loss: 1.225533 accuracy: 0.645600 | elapsed time: 36.877435 s\n",
      "Validation: loss: 1.702567 accuracy: 0.534472 | elapsed time: 8.067093 s\n",
      "epoch: 12\n",
      "loss: 0.838890 accuracy: 0.781250  [ 6400/27731/12] | elapsed time: 19.227641 s\n",
      "loss: 1.418282 accuracy: 0.625000  [12800/27731/12] | elapsed time: 8.004620 s\n",
      "loss: 1.403461 accuracy: 0.656250  [19200/27731/12] | elapsed time: 9.011537 s\n",
      "loss: 1.108996 accuracy: 0.718750  [25600/27731/12] | elapsed time: 8.705947 s\n",
      "Train: loss: 1.167329 accuracy: 0.660619 | elapsed time: 36.940242 s\n",
      "Validation: loss: 2.034640 accuracy: 0.504232 | elapsed time: 8.061261 s\n",
      "epoch: 13\n",
      "loss: 0.686803 accuracy: 0.812500  [ 6400/27731/13] | elapsed time: 19.759283 s\n",
      "loss: 1.159247 accuracy: 0.625000  [12800/27731/13] | elapsed time: 8.474767 s\n",
      "loss: 1.300149 accuracy: 0.531250  [19200/27731/13] | elapsed time: 8.009918 s\n",
      "loss: 0.819241 accuracy: 0.718750  [25600/27731/13] | elapsed time: 8.764470 s\n",
      "Train: loss: 1.118350 accuracy: 0.672648 | elapsed time: 36.699603 s\n",
      "Validation: loss: 1.782003 accuracy: 0.526458 | elapsed time: 8.039536 s\n",
      "epoch: 14\n",
      "loss: 0.751350 accuracy: 0.750000  [ 6400/27731/14] | elapsed time: 19.047571 s\n",
      "loss: 0.557859 accuracy: 0.812500  [12800/27731/14] | elapsed time: 8.850848 s\n",
      "loss: 0.922453 accuracy: 0.781250  [19200/27731/14] | elapsed time: 8.072134 s\n",
      "loss: 1.288729 accuracy: 0.625000  [25600/27731/14] | elapsed time: 8.780298 s\n",
      "Train: loss: 1.058121 accuracy: 0.686462 | elapsed time: 37.030147 s\n",
      "Validation: loss: 1.630721 accuracy: 0.565613 | elapsed time: 8.017998 s\n",
      "epoch: 15\n",
      "loss: 0.873272 accuracy: 0.781250  [ 6400/27731/15] | elapsed time: 19.696849 s\n",
      "loss: 1.038538 accuracy: 0.687500  [12800/27731/15] | elapsed time: 8.108879 s\n",
      "loss: 1.000673 accuracy: 0.656250  [19200/27731/15] | elapsed time: 8.346163 s\n",
      "loss: 1.234393 accuracy: 0.687500  [25600/27731/15] | elapsed time: 8.622176 s\n",
      "Train: loss: 1.012868 accuracy: 0.699967 | elapsed time: 36.975912 s\n",
      "Validation: loss: 2.216574 accuracy: 0.488321 | elapsed time: 8.097476 s\n",
      "epoch: 16\n",
      "loss: 0.869467 accuracy: 0.656250  [ 6400/27731/16] | elapsed time: 19.539762 s\n",
      "loss: 0.863431 accuracy: 0.718750  [12800/27731/16] | elapsed time: 8.501777 s\n",
      "loss: 0.652501 accuracy: 0.781250  [19200/27731/16] | elapsed time: 8.870073 s\n",
      "loss: 0.828840 accuracy: 0.750000  [25600/27731/16] | elapsed time: 8.090376 s\n",
      "Train: loss: 0.957268 accuracy: 0.711763 | elapsed time: 36.442378 s\n",
      "Validation: loss: 1.446362 accuracy: 0.607607 | elapsed time: 8.048551 s\n",
      "epoch: 17\n",
      "loss: 1.018392 accuracy: 0.656250  [ 6400/27731/17] | elapsed time: 19.378419 s\n",
      "loss: 1.132011 accuracy: 0.687500  [12800/27731/17] | elapsed time: 8.484535 s\n",
      "loss: 0.951495 accuracy: 0.593750  [19200/27731/17] | elapsed time: 8.644379 s\n",
      "loss: 1.284488 accuracy: 0.625000  [25600/27731/17] | elapsed time: 8.096057 s\n",
      "Train: loss: 0.903913 accuracy: 0.731447 | elapsed time: 36.623713 s\n",
      "Validation: loss: 1.460378 accuracy: 0.598576 | elapsed time: 8.062968 s\n",
      "epoch: 18\n",
      "loss: 0.802119 accuracy: 0.718750  [ 6400/27731/18] | elapsed time: 19.106572 s\n",
      "loss: 0.643913 accuracy: 0.750000  [12800/27731/18] | elapsed time: 8.395405 s\n",
      "loss: 0.547876 accuracy: 0.812500  [19200/27731/18] | elapsed time: 8.342480 s\n",
      "loss: 0.835459 accuracy: 0.750000  [25600/27731/18] | elapsed time: 8.227678 s\n",
      "Train: loss: 0.848249 accuracy: 0.741310 | elapsed time: 36.520782 s\n",
      "Validation: loss: 1.496077 accuracy: 0.589825 | elapsed time: 8.029780 s\n",
      "epoch: 19\n",
      "loss: 1.100721 accuracy: 0.625000  [ 6400/27731/19] | elapsed time: 20.271894 s\n",
      "loss: 0.608656 accuracy: 0.812500  [12800/27731/19] | elapsed time: 8.250439 s\n",
      "loss: 0.806579 accuracy: 0.812500  [19200/27731/19] | elapsed time: 8.291407 s\n",
      "loss: 0.736153 accuracy: 0.812500  [25600/27731/19] | elapsed time: 8.350336 s\n",
      "Train: loss: 0.802428 accuracy: 0.756291 | elapsed time: 36.761236 s\n",
      "Validation: loss: 1.761761 accuracy: 0.551387 | elapsed time: 8.079563 s\n"
     ]
    }
   ],
   "source": [
    "train(model,train_loader,test_loader,printstep=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43224253-3917-46f6-b286-bd8aee556097",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
